{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88813200",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# üìò Linear Algebra in Neural Networks ‚Äî Visual Notebook\n",
    "# -------------------------------------------------------\n",
    "# This notebook demonstrates how neural networks use linear algebra\n",
    "# to represent and transform data using matrices and vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e57063",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20483303",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Helper function for plotting points\n",
    "def plot_points(X, title=\"\", color=\"steelblue\"):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=color, s=30)\n",
    "    plt.axhline(0, color=\"black\", linewidth=1)\n",
    "    plt.axvline(0, color=\"black\", linewidth=1)\n",
    "    plt.title(title)\n",
    "    plt.xlim(-5, 5)\n",
    "    plt.ylim(-5, 5)\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6aabc69",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------------------------------------\n",
    "# 1Ô∏è‚É£ Representing Data as Vectors\n",
    "# -------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd19f34d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Each data point can be represented as a vector [x1, x2]\n",
    "X = np.random.randn(100, 2)\n",
    "plot_points(X, \"Raw Data: 2D Points (Vectors)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77603933",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# -------------------------------------------------------\n",
    "# 2Ô∏è‚É£ Linear Transformation (Matrix Multiplication)\n",
    "# -------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54b3c0b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Let's apply a matrix transformation: y = W * x\n",
    "# This could represent a neural network layer's weights.\n",
    "\n",
    "W = np.array([[1.5, 0.5],\n",
    "              [0.2, 1.2]])\n",
    "\n",
    "X_transformed = X.dot(W.T)\n",
    "plot_points(X_transformed, \"After Linear Transformation (Stretch/Rotate)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7b2c76",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# -------------------------------------------------------\n",
    "# 3Ô∏è‚É£ Adding a Bias (Shifting the Data)\n",
    "# -------------------------------------------------------\n",
    "\n",
    "b = np.array([1.0, -0.5])\n",
    "X_shifted = X_transformed + b\n",
    "plot_points(X_shifted, \"After Adding Bias (Shift)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6550a8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# -------------------------------------------------------\n",
    "# 4Ô∏è‚É£ Nonlinear Transformation (Activation Function)\n",
    "# -------------------------------------------------------\n",
    "\n",
    "# Let's apply a ReLU activation: ReLU(x) = max(0, x)\n",
    "X_relu = np.maximum(0, X_shifted)\n",
    "plot_points(X_relu, \"After ReLU Activation (Nonlinear Bend)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721c5b65",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# -------------------------------------------------------\n",
    "# 5Ô∏è‚É£ Combining Steps = A Neural Network Layer\n",
    "# -------------------------------------------------------\n",
    "\n",
    "def neural_layer(X, W, b):\n",
    "    return np.maximum(0, X.dot(W.T) + b)\n",
    "\n",
    "Y = neural_layer(X, W, b)\n",
    "plot_points(Y, \"A Full Layer: Linear + Bias + Nonlinear\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec065f42",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# -------------------------------------------------------\n",
    "# 6Ô∏è‚É£ Understanding the Flow\n",
    "# -------------------------------------------------------\n",
    "\n",
    "# Each layer reshapes the data (stretch ‚Üí shift ‚Üí bend)\n",
    "# making patterns clearer and easier for the next layer to use.\n",
    "\n",
    "# For example, let's simulate a second layer with new weights:\n",
    "W2 = np.array([[1.0, -0.8],\n",
    "               [0.5,  1.3]])\n",
    "b2 = np.array([-0.2, 0.7])\n",
    "\n",
    "Y2 = neural_layer(Y, W2, b2)\n",
    "plot_points(Y2, \"After Second Layer: Data Further Reshaped\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
